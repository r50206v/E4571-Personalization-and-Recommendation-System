{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark import SparkFiles\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import rand, col\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "seed = 100\n",
    "filePath = \"yelp_dataset/review_cleaned.csv\"\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2144719</th>\n",
       "      <td>qEHYU_tm4YM04a0586UPvw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-01-01 00:00:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hNwleSHcvNksIQT31569Yg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Window washing inside and out done after many ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9jdES117z1Dat4aJuGZs5w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144722</th>\n",
       "      <td>XcWlBj5oQgzKhR7Cxovj3w</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-01-01 00:02:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DfZGAhAkPMJYDdXGRjhw8A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I will admit, I do not have high expectations ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UaUVIQweBNlE_tVBCZjYdA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144725</th>\n",
       "      <td>O-uIEuv7JLUHajkemx_sVw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-01-01 00:02:35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65viXwIysYSxEyPZgRSVbQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The chicken curry I got was extremely dry. Des...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mq5rKhLMHLbUaBeZY8mY8Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144726</th>\n",
       "      <td>nqgeTj6bfIMY0v2J-vZa8A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-01-01 00:02:42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hS3phsfoP-fAZVlMomx4Kg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Really took care of me on my trip out of state...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-ELGAON2OCSBBIbGKNiYGQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144728</th>\n",
       "      <td>kd1NhNWvWo5AhBUSaGeSiw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-01 00:04:13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eaDgBBrOtvFUto5pADZwQA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gary and Chester run this 2 year old Church St...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tYxumQ3zkWje5X14LTDpcA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    business_id  cool                 date  funny  \\\n",
       "2144719  qEHYU_tm4YM04a0586UPvw   0.0  2015-01-01 00:00:30    0.0   \n",
       "2144722  XcWlBj5oQgzKhR7Cxovj3w   0.0  2015-01-01 00:02:20    0.0   \n",
       "2144725  O-uIEuv7JLUHajkemx_sVw   0.0  2015-01-01 00:02:35    1.0   \n",
       "2144726  nqgeTj6bfIMY0v2J-vZa8A   0.0  2015-01-01 00:02:42    0.0   \n",
       "2144728  kd1NhNWvWo5AhBUSaGeSiw   1.0  2015-01-01 00:04:13    0.0   \n",
       "\n",
       "                      review_id  stars  \\\n",
       "2144719  hNwleSHcvNksIQT31569Yg    5.0   \n",
       "2144722  DfZGAhAkPMJYDdXGRjhw8A    2.0   \n",
       "2144725  65viXwIysYSxEyPZgRSVbQ    1.0   \n",
       "2144726  hS3phsfoP-fAZVlMomx4Kg    5.0   \n",
       "2144728  eaDgBBrOtvFUto5pADZwQA    5.0   \n",
       "\n",
       "                                                      text  useful  \\\n",
       "2144719  Window washing inside and out done after many ...     5.0   \n",
       "2144722  I will admit, I do not have high expectations ...     0.0   \n",
       "2144725  The chicken curry I got was extremely dry. Des...     0.0   \n",
       "2144726  Really took care of me on my trip out of state...     0.0   \n",
       "2144728  Gary and Chester run this 2 year old Church St...     1.0   \n",
       "\n",
       "                        user_id  \n",
       "2144719  9jdES117z1Dat4aJuGZs5w  \n",
       "2144722  UaUVIQweBNlE_tVBCZjYdA  \n",
       "2144725  mq5rKhLMHLbUaBeZY8mY8Q  \n",
       "2144726  -ELGAON2OCSBBIbGKNiYGQ  \n",
       "2144728  tYxumQ3zkWje5X14LTDpcA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPandas = pd.read_csv(filePath, index_col=0)\n",
    "dfPandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3045862, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPandas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs: \n",
      " business_id    0\n",
      "cool           0\n",
      "date           0\n",
      "funny          0\n",
      "review_id      0\n",
      "stars          0\n",
      "text           0\n",
      "useful         0\n",
      "user_id        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [business_id, cool, date, funny, review_id, stars, text, useful, user_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"NaNs: \\n\", dfPandas.isnull().sum())\n",
    "dfPandas.reset_index(drop=True, inplace=True)\n",
    "dfPandas.loc[dfPandas.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.95, max_features=None, min_df=0.05,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_df=0.95, min_df=0.05)\n",
    "count_vectorizer.fit(dfPandas['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit(count_vectorizer.transform(dfPandas['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " 'about',\n",
       " 'after',\n",
       " 'again',\n",
       " 'all',\n",
       " 'also',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'are',\n",
       " 'area',\n",
       " 'around',\n",
       " 'as',\n",
       " 'asked',\n",
       " 'at',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bar',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'came',\n",
       " 'can',\n",
       " 'check',\n",
       " 'cheese',\n",
       " 'chicken',\n",
       " 'clean',\n",
       " 'come',\n",
       " 'coming',\n",
       " 'could',\n",
       " 'customer',\n",
       " 'day',\n",
       " 'definitely',\n",
       " 'delicious',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'different',\n",
       " 'dinner',\n",
       " 'do',\n",
       " 'don',\n",
       " 'done',\n",
       " 'down',\n",
       " 'drinks',\n",
       " 'eat',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everything',\n",
       " 'excellent',\n",
       " 'experience',\n",
       " 'favorite',\n",
       " 'feel',\n",
       " 'few',\n",
       " 'find',\n",
       " 'first',\n",
       " 'food',\n",
       " 'for',\n",
       " 'found',\n",
       " 'fresh',\n",
       " 'friendly',\n",
       " 'from',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'had',\n",
       " 'happy',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'highly',\n",
       " 'his',\n",
       " 'home',\n",
       " 'hot',\n",
       " 'how',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'just',\n",
       " 'know',\n",
       " 'last',\n",
       " 'like',\n",
       " 'little',\n",
       " 'll',\n",
       " 'location',\n",
       " 'long',\n",
       " 'looking',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'lunch',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'me',\n",
       " 'meal',\n",
       " 'menu',\n",
       " 'minutes',\n",
       " 'more',\n",
       " 'most',\n",
       " 'much',\n",
       " 'my',\n",
       " 'need',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'no',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'one',\n",
       " 'only',\n",
       " 'or',\n",
       " 'order',\n",
       " 'ordered',\n",
       " 'other',\n",
       " 'our',\n",
       " 'out',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'people',\n",
       " 'place',\n",
       " 'pretty',\n",
       " 'price',\n",
       " 'prices',\n",
       " 'quality',\n",
       " 're',\n",
       " 'really',\n",
       " 'recommend',\n",
       " 'restaurant',\n",
       " 'right',\n",
       " 'said',\n",
       " 'salad',\n",
       " 'same',\n",
       " 'sauce',\n",
       " 'say',\n",
       " 'see',\n",
       " 'service',\n",
       " 'she',\n",
       " 'should',\n",
       " 'side',\n",
       " 'since',\n",
       " 'small',\n",
       " 'so',\n",
       " 'some',\n",
       " 'something',\n",
       " 'staff',\n",
       " 'stars',\n",
       " 'still',\n",
       " 'super',\n",
       " 'sure',\n",
       " 'table',\n",
       " 'take',\n",
       " 'taste',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'they',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'this',\n",
       " 'though',\n",
       " 'time',\n",
       " 'times',\n",
       " 'to',\n",
       " 'told',\n",
       " 'too',\n",
       " 'took',\n",
       " 'tried',\n",
       " 'try',\n",
       " 'two',\n",
       " 'up',\n",
       " 'us',\n",
       " 've',\n",
       " 'vegas',\n",
       " 'very',\n",
       " 'visit',\n",
       " 'wait',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'way',\n",
       " 'we',\n",
       " 'well',\n",
       " 'went',\n",
       " 'were',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'will',\n",
       " 'with',\n",
       " 'work',\n",
       " 'worth',\n",
       " 'would',\n",
       " 'years',\n",
       " 'you',\n",
       " 'your']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidf_transformer.transform(count_vectorizer.transform(dfPandas['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3045862x233 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 110621481 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(count_vectorizer, open('yelp_dataset/countVectorizer.pkl', 'wb'))\n",
    "pickle.dump(tfidf_transformer, open('yelp_dataset/tfidfTransformer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "scipy.sparse.save_npz('yelp_dataset/textTransform.npz', tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreMatrix = pd.DataFrame(\n",
    "    data=tfidf.toarray(),\n",
    "    columns=count_vectorizer.get_feature_names(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>about</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>all</th>\n",
       "      <th>also</th>\n",
       "      <th>always</th>\n",
       "      <th>am</th>\n",
       "      <th>amazing</th>\n",
       "      <th>an</th>\n",
       "      <th>...</th>\n",
       "      <th>while</th>\n",
       "      <th>who</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>work</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 233 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  about     after  again       all  also  always   am  amazing   an  \\\n",
       "0  0.0    0.0  0.262632    0.0  0.201926   0.0     0.0  0.0      0.0  0.0   \n",
       "\n",
       "   ...  while  who  will  with      work  worth  would     years  you  your  \n",
       "0  ...    0.0  0.0   0.0   0.0  0.314621    0.0    0.0  0.341729  0.0   0.0  \n",
       "\n",
       "[1 rows x 233 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreMatrix.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreMatrix.to_csv('yelp_dataset/textTransformPandas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>TrainTest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qEHYU_tm4YM04a0586UPvw</td>\n",
       "      <td>9jdES117z1Dat4aJuGZs5w</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-01-01 00:00:30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XcWlBj5oQgzKhR7Cxovj3w</td>\n",
       "      <td>UaUVIQweBNlE_tVBCZjYdA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-01-01 00:02:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O-uIEuv7JLUHajkemx_sVw</td>\n",
       "      <td>mq5rKhLMHLbUaBeZY8mY8Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-01 00:02:35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nqgeTj6bfIMY0v2J-vZa8A</td>\n",
       "      <td>-ELGAON2OCSBBIbGKNiYGQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-01-01 00:02:42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kd1NhNWvWo5AhBUSaGeSiw</td>\n",
       "      <td>tYxumQ3zkWje5X14LTDpcA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-01-01 00:04:13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                 user_id  stars                 date  \\\n",
       "0  qEHYU_tm4YM04a0586UPvw  9jdES117z1Dat4aJuGZs5w    5.0  2015-01-01 00:00:30   \n",
       "1  XcWlBj5oQgzKhR7Cxovj3w  UaUVIQweBNlE_tVBCZjYdA    2.0  2015-01-01 00:02:20   \n",
       "2  O-uIEuv7JLUHajkemx_sVw  mq5rKhLMHLbUaBeZY8mY8Q    1.0  2015-01-01 00:02:35   \n",
       "3  nqgeTj6bfIMY0v2J-vZa8A  -ELGAON2OCSBBIbGKNiYGQ    5.0  2015-01-01 00:02:42   \n",
       "4  kd1NhNWvWo5AhBUSaGeSiw  tYxumQ3zkWje5X14LTDpcA    5.0  2015-01-01 00:04:13   \n",
       "\n",
       "   TrainTest  \n",
       "0          1  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ratings = pd.read_csv('yelp_dataset/yelp_ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.drop(['date', 'TrainTest'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3045862, 3)\n",
      "(3045862, 3)\n"
     ]
    }
   ],
   "source": [
    "print(ratings.shape)\n",
    "print(ratings.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark import SparkFiles\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import rand, col\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "seed = 100\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = \"yelp_dataset/yelp_ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset into spark RDD\n",
    "sc.addFile(filePath)\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.csv(\n",
    "    SparkFiles.get(\"yelp_ratings.csv\"), \n",
    "    header=True, \n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "sqlContext.registerDataFrameAsTable(df, \"df\")\n",
    "df = sqlContext.sql('''\n",
    "    SELECT *\n",
    "    FROM df\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+-------------------+---------+\n",
      "|         business_id|             user_id|stars|               date|TrainTest|\n",
      "+--------------------+--------------------+-----+-------------------+---------+\n",
      "|qEHYU_tm4YM04a058...|9jdES117z1Dat4aJu...|  5.0|2015-01-01 00:00:30|        1|\n",
      "|XcWlBj5oQgzKhR7Cx...|UaUVIQweBNlE_tVBC...|  2.0|2015-01-01 00:02:20|        0|\n",
      "|O-uIEuv7JLUHajkem...|mq5rKhLMHLbUaBeZY...|  1.0|2015-01-01 00:02:35|        1|\n",
      "|nqgeTj6bfIMY0v2J-...|-ELGAON2OCSBBIbGK...|  5.0|2015-01-01 00:02:42|        0|\n",
      "|kd1NhNWvWo5AhBUSa...|tYxumQ3zkWje5X14L...|  5.0|2015-01-01 00:04:13|        0|\n",
      "|JyxHvtj-syke7m9rb...|fS8z1BsG6s26wiPWF...|  3.0|2015-01-01 00:05:18|        0|\n",
      "|A029GQG1S3ekPit6c...|iWEruF6zWqoVWZ1ip...|  5.0|2015-01-01 00:06:22|        1|\n",
      "|KmsQdsAzOptMg9W7Z...|esmTJ_wex9xzYHCbW...|  5.0|2015-01-01 00:06:43|        1|\n",
      "|yEyA7uILKG97qnyx3...|N2F0ZsiSMtNm9-NBW...|  2.0|2015-01-01 00:06:52|        0|\n",
      "|ahSFUPojs9X3-1jP-...|Uwu6MCuv_YIxHL0kD...|  4.0|2015-01-01 00:12:15|        1|\n",
      "+--------------------+--------------------+-----+-------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('business_id', 'string'),\n",
       " ('user_id', 'string'),\n",
       " ('stars', 'double'),\n",
       " ('date', 'timestamp'),\n",
       " ('TrainTest', 'int')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = df.where(col('TrainTest') == 1)\n",
    "dftest = df.where(col('TrainTest') == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(business_id='qEHYU_tm4YM04a0586UPvw', user_id='9jdES117z1Dat4aJuGZs5w', stars=5.0, date=datetime.datetime(2015, 1, 1, 0, 0, 30), TrainTest=1),\n",
       " Row(business_id='O-uIEuv7JLUHajkemx_sVw', user_id='mq5rKhLMHLbUaBeZY8mY8Q', stars=1.0, date=datetime.datetime(2015, 1, 1, 0, 2, 35), TrainTest=1),\n",
       " Row(business_id='A029GQG1S3ekPit6cObcBA', user_id='iWEruF6zWqoVWZ1ipWRVJQ', stars=5.0, date=datetime.datetime(2015, 1, 1, 0, 6, 22), TrainTest=1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(business_id='XcWlBj5oQgzKhR7Cxovj3w', user_id='UaUVIQweBNlE_tVBCZjYdA', stars=2.0, date=datetime.datetime(2015, 1, 1, 0, 2, 20), TrainTest=0),\n",
       " Row(business_id='nqgeTj6bfIMY0v2J-vZa8A', user_id='-ELGAON2OCSBBIbGKNiYGQ', stars=5.0, date=datetime.datetime(2015, 1, 1, 0, 2, 42), TrainTest=0),\n",
       " Row(business_id='kd1NhNWvWo5AhBUSaGeSiw', user_id='tYxumQ3zkWje5X14LTDpcA', stars=5.0, date=datetime.datetime(2015, 1, 1, 0, 4, 13), TrainTest=0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model (Rating Average for all users and movies) Performance on Test Set\n",
      "baseline performance on test set:  1.5670219328182322\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import operator\n",
    "# using average rate as Baseline model\n",
    "meanRating = df.rdd.map(lambda x: x[2]).mean()\n",
    "baselineRmse = math.sqrt(\n",
    "    dftest.rdd.map(lambda x: (meanRating - x[2]) ** 2).reduce(operator.add) / dftest.count()\n",
    ")\n",
    "print(\"Baseline Model (Rating Average for all users and movies) Performance on Test Set\")\n",
    "print(\"baseline performance on test set: \", baselineRmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
