{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark import SparkFiles\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import rand, col\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "seed = 100\n",
    "filePath = \"yelp_dataset/review_cleaned.csv\"\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3fw2X5bZYeW9xCz_zGhOHg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-05-07 01:21:02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>G7XHMxG0bx9oBJNECG4IFg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tracy dessert had a big name in Hong Kong and ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>jlu4CztcSxrKx56ba1a5AQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>YvrylyuWgbP90RgMqZQVnQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-04-07 21:27:49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>svK3nBU7Rk8VfGorlrN52A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>You can't really find anything wrong with this...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NJlxGtouq06hhC7sS2ECYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>NyLYY8q1-H3hfsTwuwLPCg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-01-03 22:47:34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1wVA2-vQIuW_ClmXkDxqMQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great lunch today. Staff was very helpful in a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86J5DwcFk4f4In1Vxe2TvA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id  cool                 date  funny  \\\n",
       "1   NZnhc2sEQy3RmzKTZnqtwQ   0.0  2017-01-14 21:30:33    0.0   \n",
       "2   WTqjgwHlXbSFevF32_DJVw   0.0  2016-11-09 20:09:03    0.0   \n",
       "6   3fw2X5bZYeW9xCz_zGhOHg   5.0  2016-05-07 01:21:02    4.0   \n",
       "15  YvrylyuWgbP90RgMqZQVnQ   0.0  2017-04-07 21:27:49    0.0   \n",
       "16  NyLYY8q1-H3hfsTwuwLPCg   0.0  2015-01-03 22:47:34    0.0   \n",
       "\n",
       "                 review_id  stars  \\\n",
       "1   GJXCdrto3ASJOqKeVWPi6Q    5.0   \n",
       "2   2TzJjDVDEuAW6MR5Vuc1ug    5.0   \n",
       "6   G7XHMxG0bx9oBJNECG4IFg    3.0   \n",
       "15  svK3nBU7Rk8VfGorlrN52A    5.0   \n",
       "16  1wVA2-vQIuW_ClmXkDxqMQ    4.0   \n",
       "\n",
       "                                                 text  useful  \\\n",
       "1   I *adore* Travis at the Hard Rock's new Kelly ...     0.0   \n",
       "2   I have to say that this office really has it t...     3.0   \n",
       "6   Tracy dessert had a big name in Hong Kong and ...     5.0   \n",
       "15  You can't really find anything wrong with this...     0.0   \n",
       "16  Great lunch today. Staff was very helpful in a...     0.0   \n",
       "\n",
       "                   user_id  \n",
       "1   yXQM5uF2jS6es16SJzNHfg  \n",
       "2   n6-Gk65cPZL6Uz8qRm3NYw  \n",
       "6   jlu4CztcSxrKx56ba1a5AQ  \n",
       "15  NJlxGtouq06hhC7sS2ECYw  \n",
       "16  86J5DwcFk4f4In1Vxe2TvA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPandas = pd.read_csv(filePath, index_col=0)\n",
    "dfPandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3148043, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPandas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [business_id, cool, date, funny, review_id, stars, text, useful, user_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"NaNs: \", dfPandas['text'].isnull().sum())\n",
    "dfPandas.loc[dfPandas.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.95, max_features=None, min_df=0.05,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_df=0.95, min_df=0.05)\n",
    "count_vectorizer.fit(dfPandas['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit(count_vectorizer.transform(dfPandas['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " 'about',\n",
       " 'after',\n",
       " 'again',\n",
       " 'all',\n",
       " 'also',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'are',\n",
       " 'area',\n",
       " 'around',\n",
       " 'as',\n",
       " 'asked',\n",
       " 'at',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bar',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'both',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'by',\n",
       " 'came',\n",
       " 'can',\n",
       " 'check',\n",
       " 'cheese',\n",
       " 'chicken',\n",
       " 'clean',\n",
       " 'come',\n",
       " 'coming',\n",
       " 'could',\n",
       " 'customer',\n",
       " 'day',\n",
       " 'definitely',\n",
       " 'delicious',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'different',\n",
       " 'dinner',\n",
       " 'do',\n",
       " 'don',\n",
       " 'done',\n",
       " 'down',\n",
       " 'drinks',\n",
       " 'eat',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everything',\n",
       " 'excellent',\n",
       " 'experience',\n",
       " 'favorite',\n",
       " 'feel',\n",
       " 'few',\n",
       " 'find',\n",
       " 'first',\n",
       " 'food',\n",
       " 'for',\n",
       " 'found',\n",
       " 'fresh',\n",
       " 'friendly',\n",
       " 'from',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'had',\n",
       " 'happy',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'highly',\n",
       " 'his',\n",
       " 'home',\n",
       " 'hot',\n",
       " 'how',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'just',\n",
       " 'know',\n",
       " 'last',\n",
       " 'like',\n",
       " 'little',\n",
       " 'll',\n",
       " 'location',\n",
       " 'long',\n",
       " 'looking',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'lunch',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'me',\n",
       " 'meal',\n",
       " 'menu',\n",
       " 'minutes',\n",
       " 'more',\n",
       " 'most',\n",
       " 'much',\n",
       " 'my',\n",
       " 'need',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'no',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'one',\n",
       " 'only',\n",
       " 'or',\n",
       " 'order',\n",
       " 'ordered',\n",
       " 'other',\n",
       " 'our',\n",
       " 'out',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'people',\n",
       " 'place',\n",
       " 'pretty',\n",
       " 'price',\n",
       " 'prices',\n",
       " 'quality',\n",
       " 're',\n",
       " 'really',\n",
       " 'recommend',\n",
       " 'restaurant',\n",
       " 'right',\n",
       " 'said',\n",
       " 'salad',\n",
       " 'same',\n",
       " 'sauce',\n",
       " 'say',\n",
       " 'see',\n",
       " 'service',\n",
       " 'she',\n",
       " 'should',\n",
       " 'side',\n",
       " 'since',\n",
       " 'small',\n",
       " 'so',\n",
       " 'some',\n",
       " 'something',\n",
       " 'staff',\n",
       " 'stars',\n",
       " 'still',\n",
       " 'super',\n",
       " 'sure',\n",
       " 'table',\n",
       " 'take',\n",
       " 'taste',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'they',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'this',\n",
       " 'though',\n",
       " 'time',\n",
       " 'times',\n",
       " 'to',\n",
       " 'told',\n",
       " 'too',\n",
       " 'took',\n",
       " 'tried',\n",
       " 'try',\n",
       " 'two',\n",
       " 'up',\n",
       " 'us',\n",
       " 've',\n",
       " 'vegas',\n",
       " 'very',\n",
       " 'visit',\n",
       " 'wait',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'way',\n",
       " 'we',\n",
       " 'well',\n",
       " 'went',\n",
       " 'were',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'will',\n",
       " 'with',\n",
       " 'work',\n",
       " 'worth',\n",
       " 'would',\n",
       " 'years',\n",
       " 'you',\n",
       " 'your']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidf_transformer.transform(count_vectorizer.transform(dfPandas['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3148043x234 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 114857471 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(count_vectorizer, open('yelp_dataset/countVectorizer.pkl', 'wb'))\n",
    "pickle.dump(tfidf_transformer, open('yelp_dataset/tfidfTransformer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "scipy.sparse.save_npz('yelp_dataset/textTransform.npz', tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreMatrix = pd.DataFrame(\n",
    "    data=tfidf.toarray(),\n",
    "    columns=count_vectorizer.get_feature_names(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>about</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>all</th>\n",
       "      <th>also</th>\n",
       "      <th>always</th>\n",
       "      <th>am</th>\n",
       "      <th>amazing</th>\n",
       "      <th>an</th>\n",
       "      <th>...</th>\n",
       "      <th>while</th>\n",
       "      <th>who</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>work</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051035</td>\n",
       "      <td>0.06043</td>\n",
       "      <td>0.06782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055916</td>\n",
       "      <td>0.115414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16944</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  about  after  again       all     also   always   am  amazing   an  \\\n",
       "0  0.0    0.0    0.0    0.0  0.051035  0.06043  0.06782  0.0      0.0  0.0   \n",
       "\n",
       "   ...  while  who      will      with  work     worth  would  years      you  \\\n",
       "0  ...    0.0  0.0  0.055916  0.115414   0.0  0.082211    0.0    0.0  0.16944   \n",
       "\n",
       "   your  \n",
       "0   0.0  \n",
       "\n",
       "[1 rows x 234 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreMatrix.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreMatrix.to_csv('yelp_dataset/textTransformPandas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark import SparkFiles\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import rand, col\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "seed = 100\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = \"yelp_dataset/yelp_ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset into spark RDD\n",
    "sc.addFile(filePath)\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.csv(\n",
    "    SparkFiles.get(\"yelp_ratings.csv\"), \n",
    "    header=True, \n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "sqlContext.registerDataFrameAsTable(df, \"df\")\n",
    "df = sqlContext.sql('''\n",
    "    SELECT *\n",
    "    FROM df\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+-------------------+---------+\n",
      "|         business_id|             user_id|stars|               date|TrainTest|\n",
      "+--------------------+--------------------+-----+-------------------+---------+\n",
      "|NZnhc2sEQy3RmzKTZ...|yXQM5uF2jS6es16SJ...|  5.0|2017-01-14 21:30:33|        0|\n",
      "|WTqjgwHlXbSFevF32...|n6-Gk65cPZL6Uz8qR...|  5.0|2016-11-09 20:09:03|        1|\n",
      "|3fw2X5bZYeW9xCz_z...|jlu4CztcSxrKx56ba...|  3.0|2016-05-07 01:21:02|        1|\n",
      "|YvrylyuWgbP90RgMq...|NJlxGtouq06hhC7sS...|  5.0|2017-04-07 21:27:49|        1|\n",
      "|NyLYY8q1-H3hfsTwu...|86J5DwcFk4f4In1Vx...|  4.0|2015-01-03 22:47:34|        1|\n",
      "|cHdJXLlKNWixBXpDw...|JSrP-dUmLlwZiI7Dp...|  3.0|2015-04-01 16:30:00|        1|\n",
      "|6lj2BJ4tJeu7db5as...|6Fz_nus_OG4gar721...|  5.0|2017-05-26 01:23:19|        1|\n",
      "|qx6WhZ42eDKmBchZD...|DzZ7piLBF-WsJxqos...|  5.0|2017-03-27 01:14:37|        0|\n",
      "|Mem13A3C202RzT53n...|5JVY32_bmTBfIGpCC...|  5.0|2017-05-13 10:41:43|        1|\n",
      "|I4Nr-MVc26qWr08-S...|3CJUJILq7CLHk_9Or...|  4.0|2016-01-17 05:26:22|        1|\n",
      "+--------------------+--------------------+-----+-------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('business_id', 'string'),\n",
       " ('user_id', 'string'),\n",
       " ('stars', 'double'),\n",
       " ('date', 'timestamp'),\n",
       " ('TrainTest', 'int')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = df.where(col('TrainTest') == 1)\n",
    "dftest = df.where(col('TrainTest') == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(business_id='WTqjgwHlXbSFevF32_DJVw', user_id='n6-Gk65cPZL6Uz8qRm3NYw', stars=5.0, date=datetime.datetime(2016, 11, 9, 20, 9, 3), TrainTest=1),\n",
       " Row(business_id='3fw2X5bZYeW9xCz_zGhOHg', user_id='jlu4CztcSxrKx56ba1a5AQ', stars=3.0, date=datetime.datetime(2016, 5, 7, 1, 21, 2), TrainTest=1),\n",
       " Row(business_id='YvrylyuWgbP90RgMqZQVnQ', user_id='NJlxGtouq06hhC7sS2ECYw', stars=5.0, date=datetime.datetime(2017, 4, 7, 21, 27, 49), TrainTest=1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(business_id='NZnhc2sEQy3RmzKTZnqtwQ', user_id='yXQM5uF2jS6es16SJzNHfg', stars=5.0, date=datetime.datetime(2017, 1, 14, 21, 30, 33), TrainTest=0),\n",
       " Row(business_id='qx6WhZ42eDKmBchZDax4dQ', user_id='DzZ7piLBF-WsJxqosfJgtA', stars=5.0, date=datetime.datetime(2017, 3, 27, 1, 14, 37), TrainTest=0),\n",
       " Row(business_id='d_L-rfS1vT3JMzgCUGtiow', user_id='2mxBNBeFrgDszqGS5tdEHA', stars=5.0, date=datetime.datetime(2016, 7, 25, 3, 57, 19), TrainTest=0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model (Rating Average for all users and movies) Performance on Test Set\n",
      "baseline performance on test set:  1.5669363541126484\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import operator\n",
    "# using average rate as Baseline model\n",
    "meanRating = df.rdd.map(lambda x: x[2]).mean()\n",
    "baselineRmse = math.sqrt(\n",
    "    dftest.rdd.map(lambda x: (meanRating - x[2]) ** 2).reduce(operator.add) / dftest.count()\n",
    ")\n",
    "print(\"Baseline Model (Rating Average for all users and movies) Performance on Test Set\")\n",
    "print(\"baseline performance on test set: \", baselineRmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
